import io
import json
import pandas as pd
import streamlit as st
from docx import Document

from report import (
    draw_flow,
    save_markdown_report,
    save_docx_report,
)

st.set_page_config(page_title="æˆ˜ç•¥è§„åˆ’ä¸å®æ–½ Demo", layout="wide")
st.title("æˆ˜ç•¥è§„åˆ’ä¸å®æ–½çŸ¥è¯†åº“ Demo")

# è¯»å–æ–¹æ³•è®ºå…ƒæ•°æ®
with open('data/models.json', 'r', encoding='utf-8') as f:
    models_data = json.load(f)

# â€”â€” å…³é”®å­—è¯å…¸ï¼ˆç”¨äºæ–‡æœ¬æç¤ºï¼‰ â€”â€”
METHOD_KEYWORDS = {
    "PESTEL": ["æ”¿ç­–", "åˆ©ç‡", "å…³ç¨", "æ³•è§„", "ç¯ä¿", "æŠ€æœ¯", "ç¤¾ä¼š", "é€šèƒ€", "å®è§‚"],
    "FiveForces": ["ä»·æ ¼æˆ˜", "æ›¿ä»£å“", "è¿›å…¥å£å’", "ä¾›åº”å•†", "è´­ä¹°è€…", "ä»½é¢", "ç«äº‰"],
    "BCG": ["ä»½é¢", "å¢é•¿ç‡", "ç°é‡‘ç‰›", "æ˜æ˜Ÿ", "é—®é¢˜", "ç˜¦ç‹—"],
    "GE": ["å¸å¼•åŠ›", "ç«äº‰åŠ›", "èµ„æºé…ç½®"],
    "SWOT": ["ä¼˜åŠ¿", "åŠ£åŠ¿", "æœºä¼š", "å¨èƒ"],
    "BLM": ["OKR", "KPI", "ç»„ç»‡", "äººæ‰", "é‡Œç¨‹ç¢‘", "RACI", "æ‰§è¡Œ"]
}

# â€”â€” è§„åˆ™å¼•æ“ â€”â€”

def _display_name(key: str) -> str:
    mapping = {
        "FiveForces": "Porter Five Forces",
        "PESTEL": "PESTEL",
        "BCG": "BCG",
        "GE": "GE",
        "SWOT": "SWOT",
        "BLM": "BLM",
    }
    return mapping.get(key, key)


def pick_methods(feats: dict) -> list:
    methods = []
    if feats.get("is_new_market") or feats.get("macro_signals"):
        methods.append("PESTEL")
    ind = feats.get("industry_data", {}) or {}
    cr5 = ind.get("cr5"); hhi = ind.get("hhi"); price_war = bool(ind.get("price_war"))
    high_comp = (hhi is not None and hhi < 1500) or (cr5 is not None and cr5 < 40) or price_war
    if high_comp:
        methods.append("FiveForces")
    if (feats.get("bu_count") or 0) >= 2:
        methods.extend(["BCG","GE"])
    methods.append("SWOT")
    if feats.get("exec_gap") or feats.get("internal_data_ready"):
        methods.append("BLM")
    order = ["PESTEL","FiveForces","BCG","GE","SWOT","BLM"]
    seen, ordered = set(), []
    for k in order:
        if k in methods and k not in seen:
            ordered.append(_display_name(k)); seen.add(k)
    return ordered


def explain_triggers(feats: dict) -> list:
    ind = feats.get("industry_data", {}) or {}
    reasons = []
    if feats.get("is_new_market") or feats.get("macro_signals"):
        reasons.append("PESTELï¼šè¿›å…¥æ–°å¸‚åœºæˆ–å‡ºç°å®è§‚ä¿¡å·ï¼ˆis_new_market/macro_signals ä¸º Trueï¼‰")
    if (ind.get("hhi") is not None and ind.get("hhi") < 1500) or (ind.get("cr5") is not None and ind.get("cr5") < 40) or bool(ind.get("price_war")):
        reasons.append("Porter Five Forcesï¼šHHI<1500 æˆ– CR5<40 æˆ–å­˜åœ¨ä»·æ ¼æˆ˜")
    if (feats.get("bu_count") or 0) >= 2:
        reasons.append("BCG/GEï¼šbu_countâ‰¥2ï¼Œå¤šä¸šåŠ¡ç»„åˆéœ€è¦èµ„æºé…ç½®å»ºè®®")
    reasons.append("SWOTï¼šåŸºç¡€ç»¼åˆè¯Šæ–­ï¼Œé»˜è®¤æ‰§è¡Œ")
    if feats.get("exec_gap") or feats.get("internal_data_ready"):
        reasons.append("BLMï¼šå­˜åœ¨æ‰§è¡Œè½å·®æˆ–å†…éƒ¨æ•°æ®å¯ç”¨ï¼Œéœ€è¦æˆ˜ç•¥åˆ°æ‰§è¡Œé—­ç¯")
    return reasons

# â€”â€” æ–‡ä»¶è§£æ â€”â€”

def parse_excel(file) -> dict:
    try:
        df = pd.read_excel(file)
        def pick(col, cast=None):
            if col in df.columns and len(df) > 0:
                val = df.iloc[0][col]
                if cast:
                    try:
                        return cast(val)
                    except Exception:
                        return None
                return val
            return None
        return {
            "bu_count": pick("bu_count", int),
            "is_new_market": pick("is_new_market", bool),
            "macro_signals": pick("macro_signals", bool),
            "share_growth": pick("share_growth", float),
            "market_growth": pick("market_growth", float),
            "internal_data_ready": pick("internal_data_ready", bool),
            "exec_gap": pick("exec_gap", bool),
            "industry_data": {
                "cr5": pick("cr5", float),
                "hhi": pick("hhi", float),
                "price_war": pick("price_war", bool),
                "switching_cost": pick("switching_cost", str) or "med",
            }
        }
    except Exception:
        return {}


def parse_word(file) -> str:
    try:
        doc = Document(file)
        return "\n".join(p.text.strip() for p in doc.paragraphs if p.text.strip())
    except Exception:
        return ""


def extract_keywords(text: str) -> dict:
    hits = {}
    for m, kws in METHOD_KEYWORDS.items():
        hits[m] = sorted({kw for kw in kws if kw in text})
    return hits

# â€”â€” é¡µé¢å¯¼èˆª â€”â€”
st.sidebar.header("å¯¼èˆª")
page = st.sidebar.radio("é€‰æ‹©é¡µé¢", ["æ¦‚è§ˆä¸è¯´æ˜", "æ•°æ®ä¸Šä¼ ä¸ç‰¹å¾æå–", "æ–¹æ³•è®ºåº“", "ç”ŸæˆæŠ¥å‘Š"])

# æ¦‚è§ˆ
if page == "æ¦‚è§ˆä¸è¯´æ˜":
    st.subheader("æ”¯æŒçš„æ–¹æ³•è®ºæ¿å—")
    cols = st.columns(3)
    names = list(models_data.keys())
    for i, name in enumerate(names):
        with cols[i % 3]:
            st.markdown(f"**{name}**\n\n- ç®€ä»‹ï¼š{models_data[name].get('ç®€ä»‹','')}\n- åº”ç”¨åœºæ™¯ï¼š{models_data[name].get('åº”ç”¨åœºæ™¯','')}")
    with st.expander("ğŸ“„ ä¸Šä¼ æ–‡ä»¶æ ¼å¼è¯´æ˜"):
        st.markdown(
            """
            **Excelï¼ˆå¯é€‰ï¼‰**ï¼šæ¨èåˆ—ï¼š`bu_count`ã€`is_new_market`ã€`macro_signals`ã€`cr5`ã€`hhi`ã€`price_war`ã€`switching_cost`ã€`share_growth`ã€`market_growth`ã€`internal_data_ready`ã€`exec_gap`ã€‚
            
            **Wordï¼ˆå¯é€‰ï¼‰**ï¼šè‡ªç”±æ–‡æœ¬ç®€æŠ¥ï¼›ç³»ç»Ÿä¼šåšå…³é”®è¯æç¤ºï¼ˆå¦‚â€œå…³ç¨/ä»·æ ¼æˆ˜/OKRâ€ç­‰ï¼‰ã€‚
            
            **åè¯è§£é‡Š**ï¼šHHI < 1500 åˆ†æ•£ï¼Œ1500â€“2500 ä¸­ç­‰ï¼Œ>2500 é›†ä¸­ï¼›CR5 = è¡Œä¸šå‰äº”ä»½é¢ä¹‹å’Œã€‚
            """
        )

# æ•°æ®ä¸Šä¼ ä¸ç‰¹å¾æå–
elif page == "æ•°æ®ä¸Šä¼ ä¸ç‰¹å¾æå–":
    st.subheader("ä¸Šä¼ æ–‡ä»¶ä¸å‚æ•°å¡«å†™")
    col_u1, col_u2 = st.columns(2)
    with col_u1:
        excel_file = st.file_uploader("ä¸Šä¼  Excelï¼ˆå¯é€‰ï¼‰", type=["xlsx", "xls"], key="excel")
        word_file = st.file_uploader("ä¸Šä¼  Wordï¼ˆå¯é€‰ï¼‰", type=["docx"], key="word")
    with col_u2:
        st.caption("æ²¡æœ‰æ–‡ä»¶ä¹Ÿå¯ä»¥åªç”¨ä¸‹æ–¹è¡¨å•è·‘ä¸€é")

    parsed = parse_excel(excel_file) if excel_file else {}
    brief = parse_word(word_file) if word_file else ""

    st.markdown("**å…³é”®å‚æ•°**ï¼ˆå¯ç¼–è¾‘ï¼‰ï¼š")
    c1, c2 = st.columns(2)
    with c1:
        bu_count = st.number_input("ä¸šåŠ¡å•å…ƒæ•° bu_count", 1, 100, int(parsed.get("bu_count") or 1))
        is_new_market = st.checkbox("è¿›å…¥æ–°å¸‚åœº/æ–°åœ°åŒº", bool(parsed.get("is_new_market") or False))
        macro_signals = st.checkbox("å‡ºç°æ˜¾è‘—å®è§‚å˜åŠ¨", bool(parsed.get("macro_signals") or False))
        share_growth = st.number_input("ç›¸å¯¹ä»½é¢å¢é•¿ %", -100.0, 100.0, float(parsed.get("share_growth") or 0.0))
        market_growth = st.number_input("èµ›é“å¢é€Ÿ %", -100.0, 500.0, float(parsed.get("market_growth") or 0.0))
    with c2:
        cr5 = st.number_input("CR5 %", 0.0, 100.0, float(parsed.get("industry_data", {}).get("cr5") or 0.0))
        hhi = st.number_input("HHI", 0.0, 10000.0, float(parsed.get("industry_data", {}).get("hhi") or 0.0))
        price_war = st.checkbox("è¡Œä¸šå­˜åœ¨ä»·æ ¼æˆ˜", bool(parsed.get("industry_data", {}).get("price_war") or False))
        switching_cost = st.selectbox("ç”¨æˆ·è½¬æ¢æˆæœ¬", ["low", "med", "high"], index=["low","med","high"].index(str(parsed.get("industry_data", {}).get("switching_cost") or "med")))
        internal_data_ready = st.checkbox("å†…éƒ¨æ•°æ®å¯ç”¨ï¼ˆæˆæœ¬/ç»„ç»‡/æµç¨‹ï¼‰", bool(parsed.get("internal_data_ready") or False))
        exec_gap = st.checkbox("å­˜åœ¨æˆ˜ç•¥-æ‰§è¡Œè½å·®", bool(parsed.get("exec_gap") or False))

    feats = {
        "bu_count": bu_count,
        "is_new_market": is_new_market,
        "macro_signals": macro_signals,
        "share_growth": share_growth,
        "market_growth": market_growth,
        "internal_data_ready": internal_data_ready,
        "exec_gap": exec_gap,
        "industry_data": {"cr5": cr5, "hhi": hhi, "price_war": price_war, "switching_cost": switching_cost},
    }

    kw_hits = {}
    if brief:
        # ç®€æ˜“å…³é”®è¯å‘½ä¸­
        for m, kws in METHOD_KEYWORDS.items():
            kw_hits[m] = sorted({kw for kw in kws if kw in brief})
        st.markdown("**ä» Word æ–‡æœ¬å‘½ä¸­çš„å…³é”®è¯ï¼ˆæç¤ºç”¨ï¼‰**ï¼š")
        st.write(kw_hits)

    st.markdown("**æå–åˆ°çš„ç»“æ„åŒ–ç‰¹å¾**ï¼š")
    st.json(feats, expanded=False)

    st.markdown("---")
    run_top = st.button("â–¶ï¸ è¿è¡Œåˆ†æ", type="primary")
    run_side = st.sidebar.button("â–¶ï¸ è¿è¡Œåˆ†æ", key="run_side")
    if run_top or run_side:
        methods = pick_methods(feats)
        st.success("æ¨èæ–¹æ³•è®ºï¼š" + "ã€".join(methods))
        st.markdown("**è§¦å‘ä¾æ®ï¼ˆä¸ºä»€ä¹ˆè¿™ä¹ˆæ¨èï¼‰**ï¼š")
        for r in explain_triggers(feats):
            st.write("- ", r)
        st.session_state["feats"] = feats
        st.session_state["methods"] = methods
        st.session_state["kw_hits"] = kw_hits

# æ–¹æ³•è®ºåº“
elif page == "æ–¹æ³•è®ºåº“":
    st.subheader("æ–¹æ³•è®ºä¸€è§ˆ")
    model_name = st.selectbox("é€‰æ‹©æˆ˜ç•¥æ¨¡å‹", list(models_data.keys()))
    st.write("**ç®€ä»‹ï¼š**", models_data[model_name].get("ç®€ä»‹", ""))
    st.write("**åº”ç”¨åœºæ™¯ï¼š**", models_data[model_name].get("åº”ç”¨åœºæ™¯", ""))
    st.write("**åˆ†ææ­¥éª¤ï¼š**")
    for step in models_data[model_name].get("åˆ†ææ­¥éª¤", []):
        st.write("-", step)

# ç”ŸæˆæŠ¥å‘Š
elif page == "ç”ŸæˆæŠ¥å‘Š":
    st.subheader("å¯¼å‡ºæŠ¥å‘Š")
    st.caption("å°†ä¸Šä¸€é¡µçš„åˆ†æç»“æœï¼ˆæ–¹æ³•è®º/ç‰¹å¾/è§¦å‘ä¾æ®ï¼‰æ±‡æ€»ä¸º Markdown æˆ– Word æŠ¥å‘Šï¼Œå¹¶é™„æµç¨‹å›¾ã€‚")

    use_feats = st.session_state.get("feats", {})
    use_methods = st.session_state.get("methods", [])

    with st.expander("æŸ¥çœ‹å½“å‰ç»“æœç¼“å­˜"):
        st.write("æ–¹æ³•è®ºï¼š", use_methods)
        st.write("ç‰¹å¾ï¼š")
        st.json(use_feats, expanded=False)

    fmt = st.radio("é€‰æ‹©å¯¼å‡ºæ ¼å¼", ["Markdown", "Word (docx)"])
    if st.button("ç”Ÿæˆå¹¶ä¸‹è½½"):
        triggers = explain_triggers(use_feats) if use_feats else []
        flow_path = draw_flow(use_methods or [])
        if fmt == "Markdown":
            md_path = save_markdown_report(use_methods, use_feats, triggers, models_data)
            with open(md_path, 'rb') as f:
                st.download_button("ä¸‹è½½ Markdown æŠ¥å‘Š", data=f.read(), file_name="æˆ˜ç•¥åˆ†ææŠ¥å‘Š.md", mime="text/markdown")
        else:
            docx_path = save_docx_report(use_methods, use_feats, triggers, models_data)
            with open(docx_path, 'rb') as f:
                st.download_button("ä¸‹è½½ Word æŠ¥å‘Š", data=f.read(), file_name="æˆ˜ç•¥åˆ†ææŠ¥å‘Š.docx")
        st.image(flow_path, caption="åˆ†ææµç¨‹å›¾", use_container_width=True)
